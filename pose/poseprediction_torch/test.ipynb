{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-07T00:07:36.931589Z",
     "start_time": "2018-03-07T00:07:31.406824Z"
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"6\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import time\n",
    "\n",
    "from dataset import DatasetWrapper\n",
    "from model import PoseClassModel\n",
    "from utils.constants import *\n",
    "from utils.data import get_output_size, eval_class_acc, eval_euc_dists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-07T00:07:36.941573Z",
     "start_time": "2018-03-07T00:07:36.936561Z"
    }
   },
   "outputs": [],
   "source": [
    "root = '/data5/ludi/plankton_wi17/pose/poseprediction_torch/records/resnet50/2/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-07T02:12:29.238067Z",
     "start_time": "2018-03-07T02:12:29.204432Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'amp': 1.0,\n",
       " 'batch_size': 32,\n",
       " 'data': '/data3/ludi/plankton_wi17/pose/poseprediction_torch/data/',\n",
       " 'dataset_id': 0,\n",
       " 'epochs': 50,\n",
       " 'evaluate': 'False',\n",
       " 'img_dir': '/data5/Plankton_wi18/rawcolor_db2/images/',\n",
       " 'input_size': 384,\n",
       " 'lr': 0.001,\n",
       " 'lr_step_size': 15,\n",
       " 'model': 'resnet50',\n",
       " 'momentum': 0.9,\n",
       " 'pose_loss_weight': 100.0,\n",
       " 'resume': '',\n",
       " 'root': '/data5/ludi/plankton_wi17/pose/poseprediction_torch/records/',\n",
       " 'start_epoch': 0,\n",
       " 'std': 3.0,\n",
       " 'weight_decay': 0.0}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def read_meta(filename):\n",
    "    class DotDict(dict):\n",
    "        __getattr__ = dict.get\n",
    "        __setattr__ = dict.__setitem__\n",
    "        __delattr__ = dict.__delitem__\n",
    "    \n",
    "    args = DotDict()\n",
    "    for line in open(meta_file, 'r').read().splitlines():\n",
    "        if line:\n",
    "            key, value = line.split(': ')\n",
    "            try:\n",
    "                value = int(value)\n",
    "            except ValueError:\n",
    "                try:\n",
    "                    value = float(value)\n",
    "                except ValueError:\n",
    "                    pass\n",
    "            args[key] = value\n",
    "    return args\n",
    "        \n",
    "meta_file = os.path.join(root, 'meta.txt')\n",
    "args = read_meta(meta_file)\n",
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-07T00:08:48.418639Z",
     "start_time": "2018-03-07T00:07:37.036049Z"
    }
   },
   "outputs": [],
   "source": [
    "phase = TEST\n",
    "csv_filename = os.path.join(args.data, 'pose_class/data_{}_{}.csv'.format(phase, args.dataset_id))\n",
    "num_class = DatasetWrapper.get_num_class(csv_filename.format(phase))\n",
    "model = PoseClassModel(model_name=args.model, num_class=num_class)\n",
    "dataset = DatasetWrapper(phase,\n",
    "                         csv_filename=csv_filename,\n",
    "                         img_dir=args.img_dir,\n",
    "                         input_size=(args.input_size, args.input_size),\n",
    "                         output_size=get_output_size(model, args.input_size),\n",
    "                         batch_size=16,\n",
    "                         amp=args.amp,\n",
    "                         std=args.std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-07T00:09:19.519202Z",
     "start_time": "2018-03-07T00:08:48.435881Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Loading checkpoint '/data5/ludi/plankton_wi17/pose/poseprediction_torch/records/resnet50/2/checkpoints/checkpoint-15.pth.tar'\n",
      "=> Loaded checkpoint\n"
     ]
    }
   ],
   "source": [
    "def loadCheckPoint(model, filename):\n",
    "    if os.path.isfile(filename):\n",
    "        print(\"=> Loading checkpoint '{}'\".format(filename))\n",
    "        checkpoints = torch.load(filename)\n",
    "\n",
    "        gpuMode = checkpoints.get('gpu_mode', GpuMode.SINGLE)\n",
    "        if gpuMode == GpuMode.MULTI:\n",
    "            model = nn.DataParallel(model).cuda()\n",
    "        elif gpuMode == GpuMode.SINGLE:\n",
    "            model = model.cuda(0)\n",
    "        model.load_state_dict(checkpoints['state_dict'])\n",
    "        print(\"=> Loaded checkpoint\")\n",
    "    else:\n",
    "        print(\"=> no checkpoint found at '{}'\".format(filename))\n",
    "\n",
    "    return model\n",
    "\n",
    "checkpoint = os.path.join(root, 'checkpoints/checkpoint-15.pth.tar')\n",
    "model = loadCheckPoint(model, checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-07T00:09:19.585256Z",
     "start_time": "2018-03-07T00:09:19.523663Z"
    }
   },
   "outputs": [],
   "source": [
    "class Evaluator(object):\n",
    "    def __init__(self, dataset, model):\n",
    "        self.dataset = dataset\n",
    "        self.model = model\n",
    "        \n",
    "        self.mse_loss = nn.MSELoss()\n",
    "        self.cross_entropy_loss = nn.CrossEntropyLoss()\n",
    "        \n",
    "        self.phase = TEST\n",
    "\n",
    "        cudnn.benchmark = True\n",
    "\n",
    "        self.log_vars = ['loss', 'class_loss', 'pose_loss', 'class_accuracy', 'pose_error']\n",
    "\n",
    "#     def to_cuda(self):\n",
    "#         if self.gpu_mode == GpuMode.MULTI:\n",
    "#             self.model = nn.DataParallel(self.model).cuda()\n",
    "#         elif self.gpu_mode == GpuMode.SINGLE:\n",
    "#             self.model = self.model.cuda(0)\n",
    "    \n",
    "    def loadCheckPoint(model, filename):\n",
    "        if os.path.isfile(filename):\n",
    "            print(\"=> Loading checkpoint '{}'\".format(filename))\n",
    "            checkpoints = torch.load(filename)\n",
    "\n",
    "            gpuMode = checkpoints.get('gpu_mode', GpuMode.SINGLE)\n",
    "            if gpuMode == GpuMode.MULTI:\n",
    "                model = nn.DataParallel(model).cuda()\n",
    "            elif gpuMode == GpuMode.SINGLE:\n",
    "                model = model.cuda(0)\n",
    "            model.load_state_dict(checkpoints['state_dict'])\n",
    "            print(\"=> Loaded checkpoint\")\n",
    "        else:\n",
    "            print(\"=> no checkpoint found at '{}'\".format(filename))\n",
    "\n",
    "        return model\n",
    "\n",
    "    def to_variable(self, tensor):\n",
    "#         if self.gpu_mode == GpuMode.MULTI:\n",
    "#             return Variable(tensor.cuda())\n",
    "#         elif self.gpu_mode == GpuMode.SINGLE:\n",
    "        return Variable(tensor.cuda(0))\n",
    "#         else:\n",
    "#             return Variable(tensor)\n",
    "\n",
    "    def evaluate(self):\n",
    "        self.model.train(False)\n",
    "\n",
    "        running_vars = {var: 0 for var in self.log_vars}\n",
    "        total = 0\n",
    "        epoch_since = time.time()\n",
    "\n",
    "        for i, data in enumerate(self.dataset.dataloader):\n",
    "            inputs, target_class, target_map, coordinates = \\\n",
    "                data['image'], data['class_index'], data['target_map'], data['coordinates']\n",
    "            inputs, target_map, target_class = \\\n",
    "                self.to_variable(inputs), self.to_variable(target_map), self.to_variable(target_class)\n",
    "\n",
    "            outputs_class, outputs_pose = self.model(inputs)\n",
    "            loss_class = self.cross_entropy_loss(outputs_class, target_class)\n",
    "            loss_pose = self.mse_loss(outputs_pose, target_map) * args.pose_loss_weight\n",
    "            loss = loss_class + loss_pose\n",
    "\n",
    "            class_acc = eval_class_acc(outputs_class, target_class)\n",
    "            pose_err = eval_euc_dists(outputs_pose.cpu().data.numpy(), coordinates.numpy())\n",
    "\n",
    "            vars = {'loss': loss.data[0],\n",
    "                    'class_loss': loss_class.data[0],\n",
    "                    'pose_loss': loss_pose.data[0],\n",
    "                    'class_accuracy': class_acc,\n",
    "                    'pose_error': pose_err['average']}\n",
    "\n",
    "            running_vars = {var: running_vars[var] + vars[var] * inputs.size(0) for var in self.log_vars}\n",
    "            total += inputs.size(0)\n",
    "            eta = (time.time() - epoch_since) / total * (len(self.dataset) - total)\n",
    "\n",
    "            term_log = ', '.join(['{}: {:.4f}'.format(var, running_vars[var] / total) for var in self.log_vars])\n",
    "            print('{} {}/{} ({:.0f}%), {}, ETA: {:.0f}s     \\r'\n",
    "                  .format('Training' if phase == TRAIN else 'validating', total, len(self.dataset),\n",
    "                          100.0 * total / len(self.dataset), term_log, eta), end='')\n",
    "\n",
    "        epoch_vars = {var: running_vars[var] / len(self.dataset) for var in self.log_vars}\n",
    "\n",
    "        print()\n",
    "        term_log = ', '.join(['{}: {:.4f}'.format(var, epoch_vars[var]) for var in self.log_vars])\n",
    "        print('{} {} Time Elapsed: {:.0f}s'\n",
    "              .format(phase, term_log, time.time() - epoch_since))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-03-07T00:04:56.611Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validating 14752/16607 (89%), loss: 8.2773, class_loss: 7.3803, pose_loss: 0.8970, class_accuracy: 0.4174, pose_error: 111.2654, ETA: 14s     \r"
     ]
    }
   ],
   "source": [
    "evaluator = Evaluator(dataset=dataset, model=model)\n",
    "evaluator.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
